{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install torchviz","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-22T11:06:15.574899Z","iopub.execute_input":"2021-12-22T11:06:15.575598Z","iopub.status.idle":"2021-12-22T11:06:26.424873Z","shell.execute_reply.started":"2021-12-22T11:06:15.575503Z","shell.execute_reply":"2021-12-22T11:06:26.423997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install hiddenlayer","metadata":{"execution":{"iopub.status.busy":"2021-12-22T11:06:26.427114Z","iopub.execute_input":"2021-12-22T11:06:26.427627Z","iopub.status.idle":"2021-12-22T11:06:34.086895Z","shell.execute_reply.started":"2021-12-22T11:06:26.427584Z","shell.execute_reply":"2021-12-22T11:06:34.086054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import Libraries\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tarfile\nfrom tqdm.notebook import tqdm\nfrom sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\nimport seaborn as sns\nimport pandas as pd\nimport time\nfrom torchviz import make_dot\nimport hiddenlayer as hl\nfrom collections import Counter\nfrom imblearn.over_sampling import SMOTE\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision.datasets.utils import download_url\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as tt\nfrom torch.utils.data import random_split\nfrom torchvision.utils import make_grid\nfrom torchvision import transforms\nimport torchvision.models as models\nfrom torch.utils.data.sampler import SubsetRandomSampler, WeightedRandomSampler","metadata":{"execution":{"iopub.status.busy":"2021-12-22T11:06:34.08823Z","iopub.execute_input":"2021-12-22T11:06:34.088466Z","iopub.status.idle":"2021-12-22T11:06:36.839923Z","shell.execute_reply.started":"2021-12-22T11:06:34.088437Z","shell.execute_reply":"2021-12-22T11:06:36.839058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install opendatasets","metadata":{"execution":{"iopub.status.busy":"2021-12-22T11:06:36.842334Z","iopub.execute_input":"2021-12-22T11:06:36.842617Z","iopub.status.idle":"2021-12-22T11:06:44.530072Z","shell.execute_reply.started":"2021-12-22T11:06:36.842577Z","shell.execute_reply":"2021-12-22T11:06:44.529238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import opendatasets as od\n\n#volatille\n#b06bccd3d1795d29ff0b071f635f2d79\n\nimport os\nos.environ['KAGGLE_USERNAME'] = \"volatille\"\nos.environ['KAGGLE_KEY'] = \"b06bccd3d1795d29ff0b071f635f2d79\"\n!kaggle datasets download  paultimothymooney/breast-histopathology-images\n#od.download(\"https://www.kaggle.com/paultimothymooney/breast-histopathology-images\", force=True, username='volatille', key='b06bccd3d1795d29ff0b071f635f2d79') #Wczesniej wczytywałem poprzez sciezkie w systemie, po migracji na coolab zmieniłem ścieżkę.\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-22T11:06:44.532253Z","iopub.execute_input":"2021-12-22T11:06:44.532553Z","iopub.status.idle":"2021-12-22T11:06:58.118038Z","shell.execute_reply.started":"2021-12-22T11:06:44.532514Z","shell.execute_reply":"2021-12-22T11:06:58.11716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Rozpakowywuje baze danych, ukrywam output, bo za dużo śmieci\n\n!unzip breast-histopathology-images.zip","metadata":{"execution":{"iopub.status.busy":"2021-12-22T11:06:58.11963Z","iopub.execute_input":"2021-12-22T11:06:58.12021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Tworzenie bazy\n\ndata_dir = './'\nfolder_name = \"IDC_regular_ps50_idx5\"\nimage_folders = os.path.join(data_dir, folder_name)\n\ntransform = transforms.Compose([transforms.Resize((50, 50)), transforms.ToTensor()]) #Funkcja robie resize każdego pliku (50x50) oraz rzutuję na = torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] \n\nzdjecia_idc = []\nfor file in os.listdir(image_folders):\n    zdjecia_idc.append(ImageFolder(os.path.join(image_folders, file), transform=transform)) #pętla, alokacja wczesniej przyjętych zmian dla plików.\ndatasets = torch.utils.data.ConcatDataset(zdjecia_idc) #upchanie wszystkiego do datasets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\n\n#Obliczanie ile jest danych w zbiorze (IDC)\nj=0\nfor dataset in tqdm(datasets.datasets):\n    if j == 0:\n        result = Counter(dataset.targets)\n        j += 1\n    else:\n        result += Counter(dataset.targets)\n\n\nPliki_2 = os.listdir(os.path.join(data_dir, folder_name))\nprint(\" \\n Liczba Pacjentów:\", len(Pliki_2))\n\nprint(\"\"\"\\n Liczba zdjęć:\n    IDC_0 (Brak IDC)  : {}\n    IDC_i (Obecne IDC): {}\"\"\".format(result[0], result[1]))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Przygotowywanie modelu,danych itp.\nrandom_seed = 42\ntorch.manual_seed(random_seed)\n\ntest_size = 38000\ntrain_size = len(datasets) - test_size\ntrain_ds, test_ds = random_split(datasets, [train_size, test_size])\n\nval_size = 38000\ntrain_size = len(train_ds) - val_size\ntrain_ds, val_ds = random_split(train_ds, [train_size, val_size])\n\nlen(train_ds), len(val_ds), len(test_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Dane do treningu, validacji oraz testu\n#   shuffle=True, przy false może nastąpić większy błąd val_loss (w treningu sieci)\n#   pin_memory to wstawka dla conda cpu\n\ntrain_data = DataLoader(train_ds, shuffle=True, num_workers=4, pin_memory=True)\nval_data = DataLoader(val_ds, shuffle=True, num_workers=4, pin_memory=True)\ntest_data = DataLoader(test_ds, shuffle=True, num_workers=4, pin_memory=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Zapis danych dysk\n\ndef save_data(data, mode=\"train\"):\n    i = 0\n    for img, label in data:\n        folder_path = os.path.join(os.path.join(os.getcwd(), mode), str(np.array(label)[0]))\n        if not os.path.exists(folder_path):\n            os.makedirs(folder_path)\n        i += 1\n        image = transforms.ToPILImage()(img[0, :, :, :])\n        image.save(os.path.join(folder_path, mode+\"_\"+str(i)+\".jpg\"), \"JPEG\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#Save Train Data\nsave_data(train_data, mode=\"train\")\n\n# Save Validation Data\nsave_data(val_data, mode=\"validation\")\n\n# Save Test Data\nsave_data(test_data, mode=\"test\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transformacja danych /tt.ToTensor \ntrain_tfms = tt.Compose([tt.ToTensor()])\nvalid_tfms = tt.Compose([tt.ToTensor()])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = \"./\"\n\ntrain_file = os.path.join(data_dir, \"train\")\nval_file = os.path.join(data_dir, \"validation\")\ntest_file = os.path.join(data_dir, \"test\")\n\ntrain_ds = ImageFolder(train_file, train_tfms)\nval_ds = ImageFolder(val_file, valid_tfms)\ntest_ds = ImageFolder(test_file, valid_tfms)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#     Batch_size - liczba próbek propagowanych przez uczącą się sieć. Czyli jesli równe 1000, to pobiera 1000 uczy sieć, potem znów pobiera 1000-2000 (1k) i uczy sieć.\n#     problemem z batch size może być liczba próbek niepodzielna przez parametr ustawiony przez nas.\n\n\nbatch_size = 100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data loadery. Podajemy dane dla treningu, validacji, testu.\n#     Numworkers = 3, tutaj experymentalnie 3. \n#     Numworkers = 0 to znaczy że jest to główny proces\n#     Numworkers = 1, oznacza że proces podzielony i ma jednego \"podwykonawcę\" (wedługp rzeczytanych przykładów, zazwyczaj tyle wstarczy do poprawnej implementacji)\n#     Im więcej num_workers tym większe zasoby zuzywamy, a często nic nie zyskujemy. Możliwa obserwacja i wyciągnięcie wniosków poprzez wartości train_loss oraz val_loss\n\n#     Shuffle, tasujemy dane treningowe.\n\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)\nval_dl = DataLoader(val_ds, batch_size*2, num_workers=3, pin_memory=True)\ntest_dl = DataLoader(test_ds, batch_size*2, num_workers=3, pin_memory=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Funkcja wskaźnika F1 według algorytmu ###\n#   Funkcja jest testem na dokładność. Wartość 1.0 oznacza najwyższą precyzję\n\n#Funkcja oblicza wartości:\n# TP = True Positives\n# TN = True Negatives\n# FP = False Positives\n# FN = False Negatives\n\ndef F_score(output, label, threshold=0.5, beta=1):\n    prob = output > threshold\n    label = label > threshold\n\n    TP = (prob & label).sum(1).float()\n    TN = ((~prob) & (~label)).sum(1).float()\n    FP = (prob & (~label)).sum(1).float()\n    FN = ((~prob) & label).sum(1).float()\n\n    precision = torch.mean(TP / (TP + FP + 1e-12))\n    recall = torch.mean(TP / (TP + FN + 1e-12))\n    F2 = (1 + beta**2) * precision * recall / (beta**2 * precision + recall + 1e-12)\n    return F2.mean(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Klasa PyTorch zawierająca funkcję do kroku treningu modułu, kroku validacji modułu.\n# @training_step() zwraca train_loss\n# @validation_step() zwraca validation_loss\n# @validation_epoch_end() \n\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, targets = batch \n        targets = torch.reshape(targets.type(torch.cuda.FloatTensor), (len(targets), 1))\n        out = self(images)                      \n        loss = F.binary_cross_entropy(out, targets)      \n        return loss\n    \n    def validation_step(self, batch):\n        images, targets = batch\n        targets = torch.reshape(targets.type(torch.cuda.FloatTensor), (len(targets), 1))\n        out = self(images)                           # Generate predictions\n        loss = F.binary_cross_entropy(out, targets)  # Calculate loss\n        score = F_score(out, targets)\n        return {'val_loss': loss.detach(), 'val_score': score.detach() }\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_scores = [x['val_score'] for x in outputs]\n        epoch_score = torch.stack(batch_scores).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_score': epoch_score.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], last_lr: {:.4f}, train_loss: {:.4f}, val_loss: {:.4f}, val_score: {:.4f}\".format(\n            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_score']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BreastCancerResnet34(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        # Use a pretrained model\n        self.network = models.resnet34(pretrained=True)\n        # Replace last layer\n        num_ftrs = self.network.fc.in_features\n        self.network.fc = nn.Linear(num_ftrs, 1)\n    \n    def forward(self, xb):\n        return torch.sigmoid(self.network(xb))\n    \n    def freeze(self):\n        # To freeze the residual layers\n        for param in self.network.parameters():\n            param.require_grad = False\n        for param in self.network.fc.parameters():\n            param.require_grad = True\n    \n    def unfreeze(self):\n        # Unfreeze all layers\n        for param in self.network.parameters():\n            param.require_grad = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)\n\ndevice = get_default_device()\ndevice","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\ntest_dl = DeviceDataLoader(test_dl, device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\ndef fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n    \n    # Set up cutom optimizer with weight decay\n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    # Set up one-cycle learning rate scheduler\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n                                                steps_per_epoch=len(train_loader))\n    \n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            \n            # Gradient clipping\n            if grad_clip: \n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n            \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            # Record & update learning rate\n            lrs.append(get_lr(optimizer))\n            sched.step()\n        \n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = to_device(BreastCancerResnet34(), device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = [evaluate(model, val_dl)]\nhistory","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Resnet z metodą nauki 1 warstwy z zamrożeniem\n\nmodel.freeze()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 15\nmax_lr = 0.01\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = torch.optim.Adam","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nstart_time = time.time()\nhistory += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl, \n                         grad_clip=grad_clip, \n                         weight_decay=weight_decay, \n                         opt_func=opt_func)\n\ntrain_time = time.time() - start_time","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.unfreeze()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nstart_time = time.time()\nhistory += fit_one_cycle(epochs, 0.001, model, train_dl, val_dl, \n                         grad_clip=grad_clip, \n                         weight_decay=weight_decay, \n                         opt_func=opt_func)\ntrain_time += time.time() - start_time","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Blokujemy gradient, obliczanie pred. danych\n\n@torch.no_grad()\ndef predict_dl(dl, model, threshold=0.5):\n    torch.cuda.empty_cache()\n    batch_probs = []\n    for xb, _ in tqdm(dl):\n        probs = model(xb)\n        batch_probs.append(probs.cpu().detach())\n    batch_probs = torch.cat(batch_probs)\n    return [int(x) for x in batch_probs>threshold]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analyze Prediction Results\ntest_preds = predict_dl(test_dl, model)\nactual_label = test_dl.dl.dataset.targets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Macierz błedów. Obliczanie\n\nf1 = f1_score(actual_label, test_preds)\nf_score = float(np.array(F_score(torch.tensor(np.array(test_preds).reshape(len(test_preds), 1)), torch.tensor(np.array(actual_label).reshape(len(actual_label), 1)))))\naccuracy = accuracy_score(actual_label, test_preds)\ncm = confusion_matrix(actual_label, test_preds)\nreport = classification_report(actual_label, test_preds)\n\nprint(\"Model F-Score (Test Data): \", f_score)\nprint(\"Model F1-Score (Test Data): \", f1)\nprint(\"Model Accuracy: \", accuracy)\nprint(\"Confusion Matrix:\\n\", cm)\nprint(\"\\nClassification Report:\\n\", report)\n\n# Plot Confusion Matrix\ndf_cm = pd.DataFrame(cm, index = [i for i in \"01\"], columns = [i for i in \"01\"])\nplt.figure(figsize = (10,7))\nsns.set(font_scale=1.4)\nsns.heatmap(df_cm, cmap=\"Oranges\", annot=True, annot_kws={\"size\": 16})\nplt.title(\"Plot of Confusion Matrix\")\nplt.show()\nplt.savefig(\"ResNet34_CM\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}